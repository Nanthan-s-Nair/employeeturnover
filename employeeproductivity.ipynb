{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "yMXXlgaf6mDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "input_size = 6\n",
        "\n",
        "def data_preprocessing(task_1a_dataframe):\n",
        "    encoded_dataframe = task_1a_dataframe.copy()\n",
        "    columns_to_drop = ['Age', 'ExperienceInCurrentDomain']\n",
        "    encoded_dataframe.drop(columns=columns_to_drop, inplace=True)\n",
        "    categorical_columns = ['City', 'Education', 'PaymentTier', 'Gender', 'EverBenched']\n",
        "\n",
        "    label_encoders = {}\n",
        "    for col in categorical_columns:\n",
        "        label_encoder = LabelEncoder()\n",
        "        encoded_dataframe[col] = label_encoder.fit_transform(encoded_dataframe[col])\n",
        "        label_encoders[col] = label_encoder\n",
        "\n",
        "    return encoded_dataframe\n",
        "\n",
        "def identify_features_and_targets(encoded_dataframe):\n",
        "    selected_features = encoded_dataframe.drop(columns=['LeaveOrNot'])\n",
        "    target_label = encoded_dataframe['LeaveOrNot']\n",
        "\n",
        "    features_and_targets = [selected_features, target_label]\n",
        "    return features_and_targets\n",
        "\n",
        "def load_as_tensors(features_and_targets):\n",
        "    selected_features, target_label = features_and_targets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(selected_features, target_label, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "    training_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    data_loader = DataLoader(training_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    tensors_and_iterable_training_data = [X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, data_loader]\n",
        "\n",
        "    return tensors_and_iterable_training_data\n",
        "\n",
        "class SalaryPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SalaryPredictor, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, 16)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc2 = torch.nn.Linear(16, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def model_loss_function():\n",
        "    loss_function = nn.BCELoss()\n",
        "    return loss_function\n",
        "\n",
        "def model_optimizer(model):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    return optimizer\n",
        "\n",
        "def model_number_of_epochs():\n",
        "    number_of_epochs = 100  # Increase the number of epochs\n",
        "    return number_of_epochs\n",
        "\n",
        "def training_function(model, number_of_epochs, tensors_and_iterable_training_data, loss_function, optimizer):\n",
        "    X_train_data, _, y_train_data, _, data_loader = tensors_and_iterable_training_data\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    for epoch in range(number_of_epochs):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(batch_X)\n",
        "            batch_y = batch_y.view(-1, 1)\n",
        "            loss = loss_function(predictions, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "def validation_function(trained_model, tensors_and_iterable_training_data):\n",
        "    _, X_test_data, _, y_test_data, data_loader = tensors_and_iterable_training_data\n",
        "    trained_model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            batch_y = batch_y.view(-1, 1)\n",
        "            predictions = trained_model(batch_X)\n",
        "            predicted_labels = (predictions >= 0.5).float()\n",
        "            correct_predictions += (predicted_labels == batch_y).sum().item()\n",
        "            total_samples += batch_y.size(0)\n",
        "    model_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    return model_accuracy\n",
        "\n",
        "def tune_random_forest_hyperparameters(X_train, y_train):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [None, 10, 20],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=RandomForestClassifier(random_state=42),\n",
        "        param_grid=param_grid,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    task_1a_dataframe = pd.read_csv('/content/task_1a_dataset.csv')\n",
        "    encoded_dataframe = data_preprocessing(task_1a_dataframe)\n",
        "    features_and_targets = identify_features_and_targets(encoded_dataframe)\n",
        "    tensors_and_iterable_training_data = load_as_tensors(features_and_targets)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor, data_loader = tensors_and_iterable_training_data\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_tensor, y_train_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "\n",
        "    # Create DataLoader for validation (not used for training Random Forest)\n",
        "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Tune hyperparameters of the Random Forest classifier\n",
        "    best_rf = tune_random_forest_hyperparameters(X_train, y_train)\n",
        "\n",
        "    # Train the best Random Forest model\n",
        "    best_rf.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the Random Forest model on the validation set\n",
        "    val_predictions = best_rf.predict(X_val)\n",
        "    val_accuracy_rf = accuracy_score(y_val, val_predictions)\n",
        "\n",
        "    print(f\"Validation Accuracy (Random Forest): {val_accuracy_rf:.4f}\")\n",
        "\n",
        "    # Continue with neural network training (if desired)\n",
        "    model = SalaryPredictor()\n",
        "    loss_function = model_loss_function()\n",
        "    optimizer = model_optimizer(model)\n",
        "    number_of_epochs = model_number_of_epochs()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(number_of_epochs):\n",
        "        model.train()\n",
        "        for batch_X, batch_y in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(batch_X)\n",
        "            batch_y = batch_y.view(-1, 1)\n",
        "            loss = loss_function(predictions, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                batch_y = batch_y.view(-1, 1)\n",
        "                predictions = model(batch_X)\n",
        "                predicted_labels = (predictions >= 0.5).float()\n",
        "                correct_predictions += (predicted_labels == batch_y).sum().item()\n",
        "                total_samples += batch_y.size(0)\n",
        "        val_accuracy_nn = correct_predictions / total_samples\n",
        "        print(f\"Epoch {epoch+1}/{number_of_epochs}, Validation Accuracy (NN): {val_accuracy_nn:.4f}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    x = torch.tensor(X_train[0], dtype=torch.float32)\n",
        "    jitted_model = torch.jit.save(torch.jit.trace(model, (x)), \"task_1a_trained_model.pth\")\n",
        "\n",
        "    # Choose the best model based on validation accuracy\n",
        "    if val_accuracy_rf >= val_accuracy_nn:\n",
        "        best_model = best_rf\n",
        "    else:\n",
        "        best_model = model\n",
        "\n",
        "    # Evaluate the best model on the test set\n",
        "    X_test = scaler.transform(X_test_tensor)\n",
        "    test_predictions = best_model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test_tensor, test_predictions)\n",
        "\n",
        "    print(f\"Accuracy on the test set: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2svybvlDLcN",
        "outputId": "7f9e9929-8342-4a5f-a59f-e099252b6636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-db317f1a33a6>:152: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Random Forest): 0.8342\n",
            "Epoch 1/100, Validation Accuracy (NN): 0.6536\n",
            "Epoch 2/100, Validation Accuracy (NN): 0.6995\n",
            "Epoch 3/100, Validation Accuracy (NN): 0.7116\n",
            "Epoch 4/100, Validation Accuracy (NN): 0.7224\n",
            "Epoch 5/100, Validation Accuracy (NN): 0.7332\n",
            "Epoch 6/100, Validation Accuracy (NN): 0.7358\n",
            "Epoch 7/100, Validation Accuracy (NN): 0.7318\n",
            "Epoch 8/100, Validation Accuracy (NN): 0.7399\n",
            "Epoch 9/100, Validation Accuracy (NN): 0.7385\n",
            "Epoch 10/100, Validation Accuracy (NN): 0.7399\n",
            "Epoch 11/100, Validation Accuracy (NN): 0.7439\n",
            "Epoch 12/100, Validation Accuracy (NN): 0.7439\n",
            "Epoch 13/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 14/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 15/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 16/100, Validation Accuracy (NN): 0.7817\n",
            "Epoch 17/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 18/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 19/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 20/100, Validation Accuracy (NN): 0.7803\n",
            "Epoch 21/100, Validation Accuracy (NN): 0.7911\n",
            "Epoch 22/100, Validation Accuracy (NN): 0.7871\n",
            "Epoch 23/100, Validation Accuracy (NN): 0.7884\n",
            "Epoch 24/100, Validation Accuracy (NN): 0.8005\n",
            "Epoch 25/100, Validation Accuracy (NN): 0.8005\n",
            "Epoch 26/100, Validation Accuracy (NN): 0.8019\n",
            "Epoch 27/100, Validation Accuracy (NN): 0.8032\n",
            "Epoch 28/100, Validation Accuracy (NN): 0.8019\n",
            "Epoch 29/100, Validation Accuracy (NN): 0.8046\n",
            "Epoch 30/100, Validation Accuracy (NN): 0.8046\n",
            "Epoch 31/100, Validation Accuracy (NN): 0.8059\n",
            "Epoch 32/100, Validation Accuracy (NN): 0.8046\n",
            "Epoch 33/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 34/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 35/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 36/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 37/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 38/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 39/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 40/100, Validation Accuracy (NN): 0.8113\n",
            "Epoch 41/100, Validation Accuracy (NN): 0.8127\n",
            "Epoch 42/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 43/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 44/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 45/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 46/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 47/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 48/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 49/100, Validation Accuracy (NN): 0.8181\n",
            "Epoch 50/100, Validation Accuracy (NN): 0.8194\n",
            "Epoch 51/100, Validation Accuracy (NN): 0.8194\n",
            "Epoch 52/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 53/100, Validation Accuracy (NN): 0.8194\n",
            "Epoch 54/100, Validation Accuracy (NN): 0.8194\n",
            "Epoch 55/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 56/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 57/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 58/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 59/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 60/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 61/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 62/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 63/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 64/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 65/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 66/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 67/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 68/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 69/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 70/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 71/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 72/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 73/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 74/100, Validation Accuracy (NN): 0.8208\n",
            "Epoch 75/100, Validation Accuracy (NN): 0.8221\n",
            "Epoch 76/100, Validation Accuracy (NN): 0.8221\n",
            "Epoch 77/100, Validation Accuracy (NN): 0.8221\n",
            "Epoch 78/100, Validation Accuracy (NN): 0.8235\n",
            "Epoch 79/100, Validation Accuracy (NN): 0.8235\n",
            "Epoch 80/100, Validation Accuracy (NN): 0.8248\n",
            "Epoch 81/100, Validation Accuracy (NN): 0.8248\n",
            "Epoch 82/100, Validation Accuracy (NN): 0.8248\n",
            "Epoch 83/100, Validation Accuracy (NN): 0.8261\n",
            "Epoch 84/100, Validation Accuracy (NN): 0.8261\n",
            "Epoch 85/100, Validation Accuracy (NN): 0.8261\n",
            "Epoch 86/100, Validation Accuracy (NN): 0.8261\n",
            "Epoch 87/100, Validation Accuracy (NN): 0.8288\n",
            "Epoch 88/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 89/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 90/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 91/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 92/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 93/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 94/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 95/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 96/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 97/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 98/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 99/100, Validation Accuracy (NN): 0.8302\n",
            "Epoch 100/100, Validation Accuracy (NN): 0.8315\n",
            "Training complete.\n",
            "Accuracy on the test set: 0.8371\n"
          ]
        }
      ]
    }
  ]
}